{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhalak/dl_project_spices_richness_mamba/blob/main/updated_dl_project_mamba_daniel_last_one_8_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO1ipEVV_Nj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd83808c-ff51-48b6-add3-437396bb3742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting mamba-ssm\n",
            "  Downloading mamba_ssm-2.2.4.tar.gz (91 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (2.6.0+cu124)\n",
            "Collecting ninja (from mamba-ssm)\n",
            "  Using cached ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (0.8.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (4.48.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (24.2)\n",
            "Requirement already satisfied: setuptools>=61.0.0 in /usr/local/lib/python3.11/dist-packages (from mamba-ssm) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->mamba-ssm)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->mamba-ssm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->mamba-ssm) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba-ssm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mamba-ssm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba-ssm) (2025.1.31)\n",
            "Using cached ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.4-cp311-cp311-linux_x86_64.whl size=323672993 sha256=8a0be01153fa30727a9e69024fbe061eb92c7ba4416d2049c5fc3107ed91d852\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/5e/64/cfcb5dfe4f854944456e031c34953dc872af1ad7c206145d4a\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mamba-ssm\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed mamba-ssm-2.2.4 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install causal-conv1d>=1.2.0\n",
        "!pip install mamba-ssm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcTQWxkzezeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "4db10cd2-9d5f-4335-bb53-69badb8032de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-172bbad97ea0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/dl_project_data/sscape-avian-div-generalisability'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/dl_project_data/sscape-avian-div-generalisability'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/dl_project_data/sscape-avian-div-generalisability\n",
        "sys.path.append('/content/drive/MyDrive/dl_project_data/sscape-avian-div-generalisability')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgT38ANc0n4g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "def encode_birds(entry, bird_to_index, num_birds ):\n",
        "    one_hot_vector = np.zeros(num_birds, dtype=np.float32)\n",
        "    for bird in entry:\n",
        "        if bird in bird_to_index:  # Check to avoid errors with unexpected bird names\n",
        "            one_hot_vector[bird_to_index[bird]] = 1.0\n",
        "        else:\n",
        "          print(f\"dont have {bird}\")\n",
        "    if(max(one_hot_vector)==0):\n",
        "      print(f\"bad entry {entry}\")\n",
        "    else:\n",
        "      return one_hot_vector\n",
        "\n",
        "parsed_data_dir = '../npy/'\n",
        "npy_files_safe = [os.path.splitext(os.path.basename(f))[0] for f in glob.glob(f\"{parsed_data_dir}/*safe*.npy\")]\n",
        "npy_files = ['india_vggish', 'us_vggish', 'taiwan_vggish']  # Add all region files\n",
        "npy_files.extend(npy_files_safe)\n",
        "for dataset in npy_files:\n",
        "    print(dataset)\n",
        "avi = []\n",
        "for dataset in npy_files:\n",
        "    parsed_vggish_path = os.path.join(parsed_data_dir, '{}.npy'.format(dataset))\n",
        "    all_vggish_pcs = np.load(parsed_vggish_path, allow_pickle=True)\n",
        "    all_vggish_pcs = np.asarray(all_vggish_pcs)\n",
        "\n",
        "    all_vggish_pc_ids = np.asarray([pc.id for pc in all_vggish_pcs])\n",
        "    for pc in all_vggish_pcs:\n",
        "        avi.extend(pc.avi_spec_comm)\n",
        "avi_set = set(avi)\n",
        "print(avi_set)\n",
        "bird_to_index = {bird: idx for idx, bird in enumerate(sorted(avi_set))}\n",
        "\n",
        "def decode_birds(one_hot_vector, bird_to_index):\n",
        "    # Inverse the bird_to_index mapping to get the bird name from index\n",
        "    index_to_bird = {idx: bird for bird, idx in bird_to_index.items()}\n",
        "\n",
        "    # Get the indices of the birds that are present in the one-hot vector\n",
        "    bird_indices = np.where(one_hot_vector == 1)[0]\n",
        "\n",
        "    # Get the bird names from the indices\n",
        "    # Check if predicted index exists before accessing\n",
        "    birds = [index_to_bird[idx] for idx in bird_indices if idx in index_to_bird]\n",
        "\n",
        "    return birds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd2_LHn8SzkR"
      },
      "source": [
        "Generating a encoder dicoder for number of birds species to decrease the size of the output vector:\n",
        "Need to be trained only once, then the weights will be loaded each time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLGk47HaTlPK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LabelAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim=200, latent_dim=32):\n",
        "        super(LabelAutoencoder, self).__init__()\n",
        "\n",
        "        # Encoder: Compress input (200D â†’ 64D â†’ 16D)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),  # Reduce from 200D â†’ 64D\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, latent_dim)  # Further reduce to latent space (32D)\n",
        "        )\n",
        "\n",
        "        # Decoder: Expand latent space back to original size (32D â†’ 64D â†’ 200D)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)  # Encode input to latent space\n",
        "        reconstructed = self.decoder(latent)  # Decode back to original size\n",
        "        return latent, reconstructed\n",
        "\n",
        "    def decode(self, x):\n",
        "      return self.decoder(x)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3KUN5IvTPlA"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def train_decoder(train_dataset, input_dim = 200, latent_dim = 32, batch_size = 256, num_epochs = 1):\n",
        "  # Set dimensions\n",
        "    # number of birds species\n",
        "   # Compressed size\n",
        "\n",
        "  # Initialize model\n",
        "  autoencoder = LabelAutoencoder(input_dim, latent_dim)\n",
        "\n",
        "  # Define loss function (Mean Squared Error)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  # Define optimizer\n",
        "  optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)  # Learning rate of 0.001\n",
        "\n",
        "  # Number of training iterations\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    for target in dataloader:\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Encode â†’ Decode\n",
        "        latent, reconstructed = autoencoder(target[0])\n",
        "\n",
        "        # Compute reconstruction loss\n",
        "        loss = criterion(reconstructed, target[0])\n",
        "\n",
        "        # Backpropagation: Update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print loss every 10 epochs\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "    # Save the trained autoencoder\n",
        "  torch.save(autoencoder.state_dict(), \"label_autoencoder.pth\")\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ztCns3HecVP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "min_ones, max_ones = 1, 40\n",
        "num_samples = 100000\n",
        "input_dim = len(avi_set)\n",
        "\n",
        "# Create dataset\n",
        "dataset = torch.zeros(num_samples, input_dim)\n",
        "\n",
        "for i in range(num_samples):\n",
        "    num_ones = torch.randint(min_ones, max_ones + 1, (1,)).item()  # Random number of ones\n",
        "    indices = torch.randperm(input_dim)[:num_ones]  # Random positions\n",
        "    dataset[i, indices] = 1  # Set selected positions to 1\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "dataset = TensorDataset(dataset,)\n",
        "train_decoder(dataset, input_dim = len(avi_set), num_epochs=50)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td9J4VrBiH0N"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VGGishRegionDataset(Dataset):\n",
        "    def __init__(self, all_datasets, decoder = \"\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            npy_files (list): List of paths to `.npy` files for different regions.\n",
        "        \"\"\"\n",
        "        self.data = []  # Store all (pc_id, audio_feats, avi_spec_comm)\n",
        "\n",
        "\n",
        "        # Load and process each region\n",
        "        for dataset in all_datasets:\n",
        "            parsed_vggish_path = os.path.join(parsed_data_dir, '{}.npy'.format(dataset))\n",
        "            all_vggish_pcs = np.load(parsed_vggish_path, allow_pickle=True)\n",
        "            all_vggish_pcs = np.asarray(all_vggish_pcs)\n",
        "            if(decoder==\"\"):\n",
        "              all_vggish_pc_ids = np.asarray([pc.id for pc in all_vggish_pcs])\n",
        "              for pc in all_vggish_pcs:\n",
        "                  if(len(pc.avi_spec_comm)>0):\n",
        "                    self.data.append((pc.id, pc.audio_feats, encode_birds(pc.avi_spec_comm, bird_to_index, len(avi_set))))\n",
        "                    #revesed_data = pc.audio_feats[::-1].copy()\n",
        "                    #self.data.append((pc.id + \"_reversed\", revesed_data, encode_birds(pc.avi_spec_comm, bird_to_index, len(avi_set))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pc_id, audio_feats, avi_spec_comm = self.data[idx]\n",
        "        audio_feats = torch.tensor(audio_feats, dtype=torch.float32)\n",
        "\n",
        "        if avi_spec_comm is not None:\n",
        "            avi_spec_comm = torch.tensor(avi_spec_comm, dtype=torch.float32)\n",
        "            return audio_feats, avi_spec_comm, pc_id\n",
        "        else:\n",
        "            return audio_feats, pc_id\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c17T0fpi3OP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxuPFNAgoSpL"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "#At the Beginning\n",
        "def pad_at_beginning(sequences, padding_value=0.0):\n",
        "    max_len = max(seq.shape[0] for seq in sequences)  #changed because need standartization for pos_embeding\n",
        "    #max_len=1700\n",
        "    padded_seqs = []\n",
        "    for seq in sequences:\n",
        "        pad_size = max_len - seq.shape[0]\n",
        "        if(pad_size<0):\n",
        "          print(\"error\")\n",
        "        padding = torch.full((pad_size,) + seq.shape[1:], padding_value, dtype=seq.dtype)  # Handles multi-dim tensors\n",
        "        padded_seqs.append(torch.cat([padding, seq], dim=0))  # Concatenating padding at the beginning\n",
        "\n",
        "    return torch.stack(padded_seqs)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function to pad variable-length sequences.\n",
        "    \"\"\"\n",
        "    if len(batch[0]) == 3:  # If `avi_spec_comm` is included\n",
        "        sequences, avi_spec_comm, pc_ids = zip(*batch)\n",
        "        avi_spec_comm = torch.stack(avi_spec_comm)\n",
        "    else:\n",
        "        sequences, pc_ids = zip(*batch)\n",
        "        avi_spec_comm = None\n",
        "\n",
        "    # Pad sequences dynamically\n",
        "    padded_sequences = pad_at_beginning(sequences, padding_value=0.0)\n",
        "\n",
        "    return padded_sequences, avi_spec_comm, pc_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdfwwRNT3Os6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhhEav4PIKSC"
      },
      "source": [
        "Regular data generation:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDp9SCq-IPXh"
      },
      "source": [
        "Data generator thats generates the same data every time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMhDLL-eIP07"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Fix randomness for reproducibility\n",
        "torch.manual_seed(42)  # ðŸ”¹ Fix PyTorch randomness\n",
        "np.random.seed(42)      # ðŸ”¹ Fix NumPy randomness\n",
        "\n",
        "# If using CUDA, ensure deterministic behavior (optional)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# List of region `.npy` files\n",
        "parsed_data_dir = '../npy/'\n",
        "npy_files_safe = [os.path.splitext(os.path.basename(f))[0] for f in glob.glob(f\"{parsed_data_dir}/*safe*.npy\")]\n",
        "npy_files = ['india_vggish', 'us_vggish', 'taiwan_vggish']  # Add all region files\n",
        "npy_files.extend(npy_files_safe)\n",
        "\n",
        "# Initialize dataset\n",
        "dataset = VGGishRegionDataset(npy_files)\n",
        "\n",
        "# Split sizes\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - valid_size  # Ensure all data is used\n",
        "\n",
        "# ðŸ”¹ Ensure deterministic train/valid/test split\n",
        "split_generator = torch.Generator().manual_seed(42)  # Same generator for consistent split\n",
        "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size], generator=split_generator)\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}, Valid size: {len(valid_dataset)}, Test size: {len(test_dataset)}\")\n",
        "\n",
        "# ðŸ”¹ Create a generator for DataLoaders to ensure deterministic shuffling\n",
        "dataloader_generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, generator=dataloader_generator)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, generator=dataloader_generator)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, generator=dataloader_generator)\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(valid_loader))\n",
        "\n",
        "# Test a batch from the train loader\n",
        "for batch in train_loader:\n",
        "    inputs, _, ids = batch\n",
        "    print(\"Train Batch shape:\", inputs.shape)  # (batch_size, max_seq_len_in_batch, feature_dim)\n",
        "    print(\"PC IDs:\", ids)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c4_vgqXR3PF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK8LBZLPAQMI"
      },
      "outputs": [],
      "source": [
        "for t, i , l in train_loader:\n",
        "  print(t.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H46_0bM1NK1"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BzRliS-wTGI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from mamba_ssm import Mamba\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "class MambaBirdClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        device,\n",
        "        input_dim=128,  # AVGGish embedding dimension\n",
        "        hidden_dim=256,\n",
        "        n_mamba_layers=3,\n",
        "        n_classes=200,  # Number of bird species\n",
        "        dropout=0.3,\n",
        "        seq_len=1000,\n",
        "        num_skip_connections=4\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "\n",
        "        # increase the dimensionality so the network has more parameters to learn\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # Positional embedding (ensuring it's on the correct device)\n",
        "        #self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, hidden_dim, device=self.device) * 0.02)\n",
        "\n",
        "        # Mamba layers\n",
        "        self.mamba_layers = nn.ModuleList([nn.Sequential(\n",
        "            Mamba(\n",
        "                d_model=hidden_dim,       # Model dimension\n",
        "                d_state=256,               # SSM state expansion factor, responsible for long-term memory (matrix B)\n",
        "                d_conv=4,                 # Local convolution width, short-term memory (how much states can we see backward)\n",
        "                expand=2,                 # Expansion factor for feed-forward block\n",
        "                dt_min=0.001,             # Min step size\n",
        "                dt_max=0.1,               # Max step size\n",
        "                dt_init=\"random\",         # Initialization of step sizes\n",
        "                dt_scale=1.0,             # Scaling factor for step sizes\n",
        "                dt_init_floor=1e-4,       # Minimum value for dt initialization\n",
        "                bias=False                # Whether to learn bias\n",
        "            ),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.LayerNorm(hidden_dim)) for _ in range(n_mamba_layers)])\n",
        "\n",
        "\n",
        "        # Skip connection logic\n",
        "        step = seq_len // num_skip_connections\n",
        "        #self.skip_seq = torch.tensor(np.arange(start=step, stop=seq_len, step=step), dtype=torch.long, device=self.device)\n",
        "\n",
        "        # Skip connection weights and linear transformations\n",
        "        #self.skip_weights = nn.ParameterList([nn.Parameter(torch.ones(1, device=self.device)) for _ in range(len(self.skip_seq))])\n",
        "        #self.linear_trans = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(len(self.skip_seq))])\n",
        "\n",
        "        # Layer norm after Mamba layers\n",
        "        self.ln_f = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # Global pooling and classification head\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, seq_len, input_dim]\n",
        "        x = x.to(self.device)\n",
        "\n",
        "        # Project input to higher dimension, so the network can learn better how much lo weight in every kind of input\n",
        "        x = self.input_projection(x)\n",
        "        x= self.dropout(x)\n",
        "\n",
        "        # Add positional embeddings\n",
        "        #x = x + self.pos_embedding\n",
        "        #print(\"before mamba\", x.shape)\n",
        "\n",
        "        # Apply Mamba layers\n",
        "        for mamba_layer in self.mamba_layers:\n",
        "            x = mamba_layer(x)\n",
        "\n",
        "        # Apply skip connections\n",
        "        \"\"\"\n",
        "        for i, s in enumerate(self.skip_seq):\n",
        "            x_new = x.clone()\n",
        "            x_new[:, -1, :] = (self.skip_weights[i] * x[:, s, :] + x[:, -1, :]).clone()\n",
        "            x = x_new\n",
        "            \"\"\"\n",
        "        #print(\"after skip connection\", x.shape)\n",
        "        output =  x[:, -1, :]\n",
        "        # Final normalization #daniel: i dont know why we put the normalization layer here and not somewhere else\n",
        "        #output = self.ln_f(output)\n",
        "\n",
        "\n",
        "        # Global pooling (convert to [batch_size, hidden_dim, seq_len] for pooling)\n",
        "        #output = output.transpose(1, 2)\n",
        "        #output = self.pool(output).squeeze(-1)\n",
        "        #print(\"before classification\", output.shape)\n",
        "\n",
        "        # Classification\n",
        "        output = self.dropout(output)\n",
        "        logits = self.classifier(output)\n",
        "        #print(\"after classification\", logits.shape)\n",
        "\n",
        "\n",
        "        return logits\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        init.xavier_uniform_(m.weight)  # Xavier initialization\n",
        "        if m.bias is not None:\n",
        "            init.zeros_(m.bias)  # Set bias to zero\n",
        "    elif isinstance(m, nn.LayerNorm):\n",
        "        init.ones_(m.weight)  # Set LayerNorm scale to 1\n",
        "        init.zeros_(m.bias)   # Set bias to zero\n",
        "    elif isinstance(m, Mamba):\n",
        "        pass\n",
        "# Instantiate model and move to the correct device\n",
        "model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "model.apply(init_weights)\n",
        "print(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wM6JrHDjash"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `avi_set` is your list of all possible birds (labels)\n",
        "\n",
        "# To get more from our dataset - we gave each class weights for each label in avi_set - so labels with less representations will have more weights in the model\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(avi), y=avi)\n",
        "class_weight_dict = dict(zip(np.unique(avi), class_weights))\n",
        "print(class_weight_dict)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjjQ9Fgr9vv8"
      },
      "outputs": [],
      "source": [
        "def create_weights_from_train_loader(train_loader, num_birds):\n",
        "    \"\"\"\n",
        "    Creates weights based on bird frequencies in a train loader\n",
        "    where labels are already one-hot encoded. Computes both:\n",
        "    - Classification weights (per class, for BCE loss)\n",
        "    - Count weights (per total count, for L1 loss)\n",
        "\n",
        "    Args:\n",
        "        train_loader: The DataLoader containing training data with one-hot encoded labels\n",
        "        num_birds: Total number of bird classes\n",
        "\n",
        "    Returns:\n",
        "        class_weights: Tensor of weights inversely proportional to class frequency\n",
        "        count_weights: Tensor of weights inversely proportional to count frequency\n",
        "    \"\"\"\n",
        "    # Initialize count for each bird class\n",
        "    bird_counts = torch.zeros(num_birds)\n",
        "    count_distribution = {}  # To store count frequencies\n",
        "    total_samples = 0\n",
        "\n",
        "    print(\"Counting bird occurrences in train loader...\")\n",
        "    for batch in train_loader:\n",
        "        labels = batch[1]  # Assuming labels are one-hot encoded\n",
        "        batch_size = labels.size(0)\n",
        "        total_samples += batch_size\n",
        "\n",
        "        # Sum occurrences of each bird class\n",
        "        bird_counts += torch.sum(labels, dim=0)\n",
        "\n",
        "        # Compute total bird counts per sample\n",
        "        sample_counts = torch.sum(labels, dim=1).cpu().numpy()  # Total birds per sample\n",
        "\n",
        "        # Track the frequency of each unique count\n",
        "        for count in sample_counts:\n",
        "            count_distribution[count] = count_distribution.get(count, 0) + 1\n",
        "\n",
        "    # Compute classification weights (inverse frequency)\n",
        "    epsilon = 1e-5  # Small value to avoid division by zero\n",
        "    class_weights = 1.0 / (bird_counts + epsilon)\n",
        "    class_weights = class_weights / torch.sum(class_weights) * num_birds\n",
        "    class_weights = torch.clamp(class_weights, max=5.0)  # Cap extreme values\n",
        "\n",
        "    # Compute L1 count weights (inverse frequency)\n",
        "    max_count = max(count_distribution.keys()) if count_distribution else 1\n",
        "    max_count = int(max_count)\n",
        "    count_weights = torch.zeros((max_count + 1))  # Ensure space for all counts\n",
        "\n",
        "    for count, freq in count_distribution.items():\n",
        "        print(f\"count {count} freq {freq}\")\n",
        "        count_weights[int(count)] = 1.0 / (freq + epsilon)  # Inverse frequency\n",
        "\n",
        "    # Normalize count weights\n",
        "    count_weights = count_weights / torch.sum(count_weights) * len(count_distribution)\n",
        "    count_weights = torch.clamp(count_weights, max=5.0)  # Cap extreme values\n",
        "\n",
        "    print(f\"Generated class weights and count weights.\")\n",
        "\n",
        "    return class_weights, count_weights\n",
        "\n",
        "\n",
        "# Usage example\n",
        "num_birds = len(bird_to_index)\n",
        "class_weights, count_weights = create_weights_from_train_loader(train_loader, len(avi_set))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN5JhRnE-GDe"
      },
      "outputs": [],
      "source": [
        "def weighted_focal_loss(probs, targets, class_weights, gamma=2.0, fn_penalty=2.0):\n",
        "    \"\"\"\n",
        "    Focal loss to address class imbalance, with weighting and false negative penalty.\n",
        "\n",
        "    Args:\n",
        "        probs: Sigmoid probabilities [batch_size, n_classes]\n",
        "        targets: Binary targets [batch_size, n_classes]\n",
        "        class_weights: Per-class weights [n_classes]\n",
        "        gamma: Focusing parameter (higher means more focus on hard examples)\n",
        "        fn_penalty: Multiplier for false negative errors (higher means more penalty)\n",
        "    \"\"\"\n",
        "    # Convert to device of other tensors\n",
        "    class_weights = class_weights.to(probs.device)\n",
        "\n",
        "    # Calculate focal loss components\n",
        "    p_t = probs * targets + (1 - probs) * (1 - targets)\n",
        "    ce_loss = -torch.log(p_t + 1e-8)  # Add small epsilon to prevent log(0)\n",
        "\n",
        "    # Calculate the base focal loss\n",
        "    focal = (1 - p_t) ** gamma * ce_loss\n",
        "\n",
        "    # Create a mask for false negatives (where target=1 but prediction is low)\n",
        "    false_neg_mask = targets * (1 - probs)\n",
        "\n",
        "    # Apply the false negative penalty\n",
        "    # This increases the loss for false negatives by the fn_penalty factor\n",
        "    penalty_multiplier = 1.0 + (fn_penalty - 1.0) * false_neg_mask\n",
        "\n",
        "    # Apply both class weights and false negative penalty\n",
        "    weighted_focal = focal * class_weights.unsqueeze(0) * penalty_multiplier\n",
        "\n",
        "    return weighted_focal.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HUV5tZtQIJe"
      },
      "outputs": [],
      "source": [
        "def false_positive_negative(target, preds):\n",
        "  hit = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  for i,t in enumerate(target):\n",
        "    for j, r in enumerate(t):\n",
        "      if(preds[i][j]==target[i][j]):\n",
        "        hit+=1\n",
        "      if(preds[i][j]==1 and target[i][j]==0):\n",
        "        fn+=1\n",
        "      if(preds[i][j]==0 and target[i][j]==1):\n",
        "        fp+=1\n",
        "  return hit, fp, fn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZrRWqkqBgIR"
      },
      "outputs": [],
      "source": [
        "def binary_output(x):\n",
        "    return torch.sigmoid(x)   # maybe add (x > 0.5).float()\n",
        "def calculate_y_mean(loader):\n",
        "    sum = 0\n",
        "    count = 0\n",
        "    for _, l, _ in loader:\n",
        "      s =  torch.sum(l, dim=1)\n",
        "      sum +=torch.sum(s)\n",
        "      count += len(s)\n",
        "    return sum/count\n",
        "\n",
        "def calculate_r2(y_pred, y_true, y_mean):\n",
        "  sum_distances_mean = torch.sum((y_mean-y_true)**2)\n",
        "  sum_distances_pred = torch.sum((y_pred-y_true)**2)\n",
        "  return sum_distances_mean, sum_distances_pred\n",
        "\n",
        "\n",
        "def train_mamba(model, train_loader, batch_size, vector_dim, device, optimizer, regular_bce, scheduler, train_mean =0, loss_type_weight = 0.6):\n",
        "    \"\"\"\n",
        "    Train the model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model to evaluate.\n",
        "        train_loader: DataLoader for the training dataset.\n",
        "        batch_size (int): Batch size for evaluation.\n",
        "        vector_dim (int): Dimensionality of the output vectors.\n",
        "        device: The device (CPU/GPU) to run the evaluation on.\n",
        "\n",
        "    Returns:\n",
        "        float: The average loss over the training epoch dataset.\n",
        "\n",
        "    \"\"\"\n",
        "    #init\n",
        "    batch, dim = batch_size, vector_dim\n",
        "    #Start model training\n",
        "    model.train()\n",
        "    loss_epoch = 0\n",
        "    # Modify the loss function to include class weights\n",
        "    class_weights_tensor = torch.tensor(data=class_weights, dtype=torch.float32).to(device)\n",
        "    if(regular_bce):\n",
        "      bce_loss_birds = nn.BCEWithLogitsLoss(class_weights_tensor)\n",
        "    mse_loss_count = nn.MSELoss()\n",
        "    correct_predictions = 0\n",
        "    correct_count_predictions=0\n",
        "    total_samples = 0\n",
        "    i = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    hit = 0\n",
        "    madad = 0\n",
        "    pred_cnt = 0\n",
        "    total_gueses=0\n",
        "    r2_pred =0\n",
        "    r2_mean=0\n",
        "    for (feats,target, ids) in train_loader:\n",
        "      target = target.to(device)\n",
        "      targets_count = torch.sum(target, dim=1)\n",
        "      logits = model(feats.to(device))\n",
        "      logits_count = torch.sum(binary_output(logits), dim=1)\n",
        "      # Convert class weights into a tensor\n",
        "      if(regular_bce==False):\n",
        "        probs = torch.sigmoid(logits)\n",
        "        classification_loss = weighted_focal_loss(\n",
        "            probs=probs,\n",
        "            targets=target,\n",
        "            class_weights=class_weights,\n",
        "            gamma=2,\n",
        "            fn_penalty=2\n",
        "        )\n",
        "      else:\n",
        "        classification_loss=  bce_loss_birds(logits, target)\n",
        "      loss = loss_type_weight*classification_loss + (1-loss_type_weight)*mse_loss_count(logits_count, targets_count)\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Compute the loss\n",
        "      loss_epoch += loss.item()\n",
        "      # Compute accuracy (assumes binary classification for BCE loss)\n",
        "      sum_distances_mean, sum_distances_pred = calculate_r2(logits_count, targets_count, train_mean)\n",
        "      r2_pred+=sum_distances_pred\n",
        "      r2_mean+=sum_distances_mean\n",
        "      preds = (binary_output(logits) > 0.5).float()  # Convert logits to binary predictions\n",
        "      correct_predictions += (preds == target).sum().item()\n",
        "      logits_count_for_acc = torch.sum(preds, dim=1)\n",
        "      correct_count_predictions +=(logits_count_for_acc==targets_count).sum().item()\n",
        "      total_samples += target.shape[0]\n",
        "      madad += torch.sum(torch.abs(targets_count-logits_count)/targets_count) #NEED TO ADD - COUNT ERROR PERCENT - HOW FAR THE AMOUNT OF BIRDS WE COUND FROM THE AMOUNT OF ACTUAL COUNT TARGET\n",
        "      preds_np = preds.cpu().numpy()\n",
        "      target_np = target.cpu().numpy()\n",
        "      count_positives =false_positive_negative(target, preds)\n",
        "      hit+=count_positives[0]\n",
        "      FP+=count_positives[1]\n",
        "      FN+=count_positives[2]\n",
        "      # Print example predictions\n",
        "      for i_pred in range(len(preds_np)):\n",
        "          decoded_pred = decode_birds(preds_np[i_pred], bird_to_index)  # Decoded prediction\n",
        "          decoded_target = decode_birds(target_np[i_pred], bird_to_index)  # Decoded target\n",
        "          if(i==103) and (i_pred==0):\n",
        "              print(f\"Item {i_pred}:\")\n",
        "              print(f\"Predicted Birds: {decoded_pred}\")\n",
        "              print(f\"Target Birds: {decoded_target}\")\n",
        "\n",
        "\n",
        "      #count how many of the target birds were identified\n",
        "          for j in decoded_target:\n",
        "            if j in decoded_pred:\n",
        "              pred_cnt = pred_cnt + 1\n",
        "      #print the identified and target bird names\n",
        "      if (i == 103):\n",
        "        #print(\"target count: \", targets_count)\n",
        "        #print(\"logits count: \", logits_count_for_acc)\n",
        "        print(\"number of target birds that where identified: \", pred_cnt, \"out of \", torch.sum(logits_count_for_acc), \"number of targert birds\")\n",
        "      total_gueses +=torch.sum(logits_count_for_acc)\n",
        "      i = i+1\n",
        "    avg_loss = target.shape[0] * loss_epoch / len(train_loader)\n",
        "    correct = {\"avg_loss\": avg_loss,\n",
        "                \"bird classifier\":correct_predictions/(total_samples*target.shape[1]),\n",
        "               \"count\":correct_count_predictions/total_samples,\n",
        "               \"count_error\": madad/total_samples,\n",
        "               \"idf_perc\":pred_cnt /(total_gueses + 1e-8),\n",
        "               \"r2\":  1-(r2_pred/ (r2_mean + 1e-8)),\n",
        "               \"fp\": FP/total_samples,\n",
        "               \"fn\": FN/total_samples}\n",
        "    return model, avg_loss, correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anA92H4SdTFJ"
      },
      "outputs": [],
      "source": [
        "def eval_mamba(model, eval_loader, batch_size, vector_dim, device,  val_mean =0, loss_type_weight = 0.6):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model to evaluate.\n",
        "        eval_loader: DataLoader for the evaluation dataset.\n",
        "        batch_size (int): Batch size for evaluation.\n",
        "        vector_dim (int): Dimensionality of the output vectors.\n",
        "        device: The device (CPU/GPU) to run the evaluation on.\n",
        "\n",
        "    Returns:\n",
        "        float: The average loss over the evaluation dataset.\n",
        "        float: The accuracy of the model (if applicable).\n",
        "    \"\"\"\n",
        "    # Initialize evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Convert class weights into a tensor\n",
        "    #class_weights_tensor = torch.tensor([class_weight_dict.get(bird, 1.0) for bird in avi_set], dtype=torch.float32).to(device)\n",
        "\n",
        "    # Modify the loss function to include class weights\n",
        "    class_weights_tensor = torch.tensor(data=class_weights, dtype=torch.float32).to(device)\n",
        "    bce_loss_birds = nn.BCEWithLogitsLoss(class_weights_tensor)\n",
        "    mse_loss_count = nn.MSELoss()\n",
        "    correct_predictions = 0\n",
        "    correct_count_predictions=0\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "    i = 0\n",
        "    madad = 0\n",
        "    hit=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    pred_cnt = 0\n",
        "    total_gueses=0\n",
        "    r2_pred =0\n",
        "    r2_mean=0\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        for (feats,target, ids) in eval_loader:\n",
        "            total_count =0\n",
        "            total_predicted_count =0\n",
        "            target = target.to(device)\n",
        "            targets_count = torch.sum(target, dim=1)\n",
        "            logits = model(feats.to(device))\n",
        "            logits_count = torch.sum(binary_output(logits), dim=1)\n",
        "            # Convert class weights into a tensor\n",
        "            loss_birds = bce_loss_birds(logits, target)\n",
        "            loss_count = mse_loss_count(logits_count, targets_count)\n",
        "            loss = loss_type_weight*loss_birds + (1-loss_type_weight)*loss_count\n",
        "            # Compute the loss\n",
        "            total_loss += loss.item()\n",
        "            sum_distances_mean, sum_distances_pred = calculate_r2(logits_count, targets_count, val_mean)\n",
        "            r2_pred+=sum_distances_pred\n",
        "            r2_mean+=sum_distances_mean\n",
        "            preds = (binary_output(logits) > 0.5).float()  # Convert logits to binary predictions\n",
        "            count_positives =false_positive_negative(target, preds)\n",
        "            hit+=count_positives[0]\n",
        "            FP+=count_positives[1]\n",
        "            FN+=count_positives[2]\n",
        "            correct_predictions += (preds == target).sum().item()\n",
        "            logits_count_for_acc = torch.sum(preds, dim=1)\n",
        "            correct_count_predictions +=(logits_count_for_acc==targets_count).sum().item()\n",
        "            total_samples += target.shape[0]\n",
        "            madad += torch.sum(torch.abs(targets_count-logits_count)/targets_count) #NEED TO ADD - COUNT ERROR PERCENT - HOW FAR THE AMOUNT OF BIRDS WE COUND FROM THE AMOUNT OF ACTUAL COUNT TARGET\n",
        "            preds_np = preds.cpu().numpy()\n",
        "            target_np = target.cpu().numpy()\n",
        "            # Print example predictions\n",
        "            for i_pred in range(len(preds_np)):\n",
        "                decoded_pred = decode_birds(preds_np[i_pred], bird_to_index)  # Decoded prediction\n",
        "                decoded_target = decode_birds(target_np[i_pred], bird_to_index)  # Decoded target\n",
        "                if(i==5) and (i_pred==0):\n",
        "                    print(f\"Item {i_pred}:\")\n",
        "                    print(f\"Predicted Birds: {decoded_pred}\")\n",
        "                    print(f\"Target Birds: {decoded_target}\")\n",
        "            #count how many of the target birds were identified\n",
        "                for j in decoded_target:\n",
        "                  if j in decoded_pred:\n",
        "                    pred_cnt = pred_cnt + 1\n",
        "            #print the identified and target bird names\n",
        "            if (i == 10):\n",
        "              print(\"target count: \", targets_count)\n",
        "              print(\"logits count: \", logits_count_for_acc)\n",
        "              print(\"number of target birds that where identified: \", pred_cnt, \"out of \", torch.sum(logits_count_for_acc), \"number of targert birds\")\n",
        "            total_gueses +=torch.sum(logits_count_for_acc)\n",
        "            i = i+1\n",
        "        avg_loss = target.shape[0] * total_loss / len(eval_loader)\n",
        "        correct = {\"avg_loss\": avg_loss,\n",
        "                \"bird classifier\":correct_predictions/(total_samples*target.shape[1]),\n",
        "               \"count\":correct_count_predictions/total_samples,\n",
        "               \"count_error\": madad/total_samples,\n",
        "               \"idf_perc\":pred_cnt /(total_gueses + 1e-8),\n",
        "               \"r2\":  1-(r2_pred/ (r2_mean + 1e-8)),\n",
        "               \"fp\": FP/(total_samples*target.shape[1]),\n",
        "               \"fn\": FN/(total_samples*target.shape[1])}\n",
        "        return model, avg_loss, correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG15er8v8uFY"
      },
      "source": [
        "Function for printing the graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbg6QKa98zXg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid=None, title=\"\"):\n",
        "    \"\"\"\n",
        "    Plots idf_perc and count_error over epochs, indicating changes in learning rate and alpha.\n",
        "    If correct_valid is provided, it also plots the validation metrics.\n",
        "\n",
        "    Parameters:\n",
        "        correct_train (list of dict): List where each dictionary contains\n",
        "        'learning_rate', 'alpha', 'idf_perc', and 'count_error'.\n",
        "        correct_valid (list of dict, optional): Same format as correct_train, but for validation.\n",
        "    \"\"\"\n",
        "    epochs = list(range(1, len(correct_train) + 1))\n",
        "    idf_perc_train = [entry['idf_perc'].detach().cpu().numpy() if hasattr(entry['idf_perc'], 'cpu') else entry['idf_perc'] for entry in correct_train]\n",
        "    count_error_train = [entry['count_error'].detach().cpu().numpy() if hasattr(entry['count_error'], 'cpu') else entry['count_error'] for entry in correct_train]\n",
        "    r2 = [entry['r2'].detach().cpu().numpy() if hasattr(entry['count_error'], 'cpu') else entry['count_error'] for entry in correct_train]\n",
        "    learning_rates = [entry['learning_rate'] for entry in correct_train]\n",
        "    alphas = [entry['alpha'] for entry in correct_train]\n",
        "\n",
        "    if correct_valid:\n",
        "        idf_perc_valid = [entry['idf_perc'].detach().cpu().numpy() if hasattr(entry['idf_perc'], 'cpu') else entry['idf_perc'] for entry in correct_valid]\n",
        "        count_error_valid = [entry['count_error'].detach().cpu().numpy() if hasattr(entry['count_error'], 'cpu') else entry['count_error'] for entry in correct_valid]\n",
        "        r2_valid = [entry['r2'].detach().cpu().numpy() if hasattr(entry['count_error'], 'cpu') else entry['count_error'] for entry in correct_valid]\n",
        "\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(10, 8))\n",
        "\n",
        "    # Function to annotate parameter changes\n",
        "    def annotate_changes(values, axis, label):\n",
        "        color = \"gray\" if label == \"Alpha\" else \"black\"\n",
        "        prev_value = values[0]\n",
        "        for i, value in enumerate(values):\n",
        "            if value != prev_value:\n",
        "                axis.axvline(i + 1, color=color, linestyle='--', alpha=0.6)\n",
        "                axis.text(i + 1, max(axis.get_ylim()) * 0.5, f'{value:.2f}',\n",
        "                          rotation=0, verticalalignment='top', fontsize=10, color='black')\n",
        "                prev_value = value\n",
        "\n",
        "    # Plot idf_perc\n",
        "    axes[0].plot(epochs, idf_perc_train, marker='o', linestyle='-', color='b', label='Train idf_perc')\n",
        "    if correct_valid:\n",
        "        axes[0].plot(epochs, idf_perc_valid, marker='o', linestyle='--', color='g', label='Valid idf_perc')\n",
        "    axes[0].set_title(f'{title} IDF Percentage Over Epochs')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('idf_perc')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid()\n",
        "    annotate_changes(alphas, axes[0], 'Alpha')\n",
        "\n",
        "   # Plot count_error\n",
        "    axes[1].plot(epochs, count_error_train, marker='s', linestyle='-', color='r', label='Train count_error')\n",
        "    if correct_valid:\n",
        "        axes[1].plot(epochs, count_error_valid, marker='s', linestyle='--', color='m', label='Valid count_error')\n",
        "    axes[1].set_title(f'{title} Count Error Over Epochs')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('count_error')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid()\n",
        "    #annotate_changes(learning_rates, axes[1], 'LR')\n",
        "    annotate_changes(alphas, axes[1], 'Alpha')\n",
        "\n",
        "    # Plot R2\n",
        "    axes[2].plot(epochs, r2, marker='s', linestyle='-', color='r', label='Train')\n",
        "    if correct_valid:\n",
        "        axes[2].plot(epochs, r2_valid, marker='s', linestyle='--', color='m', label='Valid')\n",
        "    axes[2].set_title(f'{title} R2 Over Epochs')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('R2')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid()\n",
        "    #annotate_changes(learning_rates, axes[2], 'LR')\n",
        "    annotate_changes(alphas, axes[2], 'Alpha')\n",
        "    plt.savefig(f'{title}.png')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBj9JLCfm-2b"
      },
      "outputs": [],
      "source": [
        "a = ['American Goldfinch', 'Black-capped Chickadee', 'Blue Jay', 'Chestnut-backed Scimitar Babbler', 'Mallard', 'Mourning Dove', 'Red-winged Blackbird', 'Rusty Blackbird']\n",
        "b = ['American Goldfinch', 'American Tree Sparrow', 'Black-capped Chickadee', 'Blue Jay', 'Canada Goose', 'Dark-eyed Junco', 'Hairy Woodpecker', 'House Finch', 'Mallard', 'Mourning Dove', 'Northern Cardinal', 'Purple Finch', 'Song Sparrow', 'White-breasted Nuthatch', 'White-throated Sparrow']\n",
        "cnt = [ 0.14705882966518402, 0.0714285746216774, 0.0, 0.0, 0.0, 0.6666666865348816, 0.0, 0.6666666865348816, 0.3333333432674408, 0.0, 0.0, 0.5, 0.6666666865348816, 0.6000000238418579, 0.8333333730697632, 0.30000001192092896, 0.375, 0.2857142984867096, 0.5714285969734192, 0.0, 0.4000000059604645, 0.0, 0.4000000059604645, 0.7777777910232544, 0.0, 0.625, 0.3333333432674408, 0.6000000238418579, 0.25, 0.0, 0.4285714626312256]\n",
        "np.average(cnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieRNSz1qawTW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def new_alpha(alpha, changing_alpha, epoch, max_epoch, validation_loss):\n",
        "  \"\"\"\n",
        "  changing alpha -\n",
        "   0: no change\n",
        "   1: increase every 2 epochs,\n",
        "   2: decrease every 2 epochs,\n",
        "   3: increase depending on eval loss function,\n",
        "   4: decrease depending on eval loss functio\n",
        "  \"\"\"\n",
        "  if(changing_alpha==0):\n",
        "    return alpha, epoch<max_epoch\n",
        "  if(epoch%2==0 and changing_alpha in [1,2]):\n",
        "    if(changing_alpha==2):\n",
        "      return alpha*0.8, epoch<max_epoch and alpha*0.8>0.1\n",
        "    if(changing_alpha==1):\n",
        "      if(alpha!=0):\n",
        "        return alpha*1.2, epoch<max_epoch and alpha*1.2<0.9\n",
        "      else:\n",
        "        return 0.01+alpha*1.2, epoch<max_epoch\n",
        "  if(epoch>2):\n",
        "    if(alpha>0.5 and np.abs(validation_loss[-1]-validation_loss[-2])<20 and np.abs(validation_loss[-1]-validation_loss[-3])<20):\n",
        "      if(changing_alpha==4):\n",
        "        return alpha*0.85, epoch<max_epoch and alpha*0.85>0.05\n",
        "      if(changing_alpha==2):\n",
        "        if(alpha!=0):\n",
        "          return alpha*1.2, epoch<max_epoch and alpha*1.2<0.9\n",
        "        else:\n",
        "          return 0.01+alpha*1.2, epoch<max_epoch\n",
        "    if(alpha<0.5 and np.abs(validation_loss[-1]-validation_loss[-2])<50 and np.abs(validation_loss[-1]-validation_loss[-3])<50):\n",
        "      if(changing_alpha==4):\n",
        "        return alpha*0.85, epoch<max_epoch and alpha*0.85>0.05\n",
        "      if(changing_alpha==2):\n",
        "        if(alpha!=0):\n",
        "          return alpha*1.2, epoch<max_epoch and alpha*1.2<0.9\n",
        "        else:\n",
        "          return 0.01+alpha*1.2, epoch<max_epoch\n",
        "  return alpha, epoch<max_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvZEKF93enzU"
      },
      "outputs": [],
      "source": [
        "def train_and_eval_mamba(model, train_loader, valid_loader, regular_bce, alpha, vector_dim =128, max_epochs = 10 , device = device, model_name=\"\", changing_alpha=0, lr=5e-4):\n",
        "    \"\"\"\n",
        "    Train and evaluate the model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model to evaluate.\n",
        "        train_loader: DataLoader for the training dataset.\n",
        "    returns:\n",
        "        arr: array of losses for each epoch training\n",
        "        arr: array of losses for each epoch validation\n",
        "    \"\"\"\n",
        "    train_loss_arr = []\n",
        "    valid_loss_arr = []\n",
        "    correct_train =[]\n",
        "    correct_valid = []\n",
        "    idf_birds_perc = []  #the percentage of birds from the garget that were identified, every epoch we compute it from only one sequence\n",
        "    epoch = 0\n",
        "    min_count_error = np.inf\n",
        "    csv_file_train = f'{model_name}_train.csv'\n",
        "    csv_file_eval = f'{model_name}_eval.csv'\n",
        "    run = True\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "    train_mean = calculate_y_mean(train_loader)\n",
        "    eval_mean = calculate_y_mean(valid_loader)\n",
        "    while (run):\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        model, train_loss, correct = train_mamba(model, train_loader,  32, train_mean=train_mean, scheduler=scheduler, optimizer=optimizer, vector_dim =128, device = device, loss_type_weight = alpha, regular_bce=regular_bce)\n",
        "        correct[\"epoch\"] = epoch\n",
        "        correct[\"alpha\"] = alpha\n",
        "        correct[\"learning_rate\"] = optimizer.param_groups[0]['lr']\n",
        "        if np.isnan(train_loss):\n",
        "            print(f\"NaN detected in loss at Epoch {epoch}. Stopping training.\")\n",
        "            break\n",
        "        train_loss_arr.append(train_loss)\n",
        "        correct_train.append(correct)\n",
        "        df = pd.DataFrame([correct])\n",
        "        df.to_csv(csv_file_train, mode='a', header=not pd.io.common.file_exists(csv_file_train), index=False)\n",
        "        print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f} count accuracy {correct['count']}, bird prediction accuracy {correct['bird classifier']}, count_error: {correct['count_error']}\")\n",
        "        model , valid_loss, correct = eval_mamba(model, valid_loader,  32, vector_dim =128, val_mean=eval_mean, device = device, loss_type_weight = alpha)\n",
        "        print(f\"Epoch {epoch} - Valid Loss: {valid_loss:.4f} count accuracy {correct['count']}, bird prediction accuracy {correct['bird classifier']}, count_error: {correct['count_error']}, , alpha: {alpha}\")\n",
        "        correct[\"epoch\"] = epoch\n",
        "        correct[\"alpha\"] = alpha\n",
        "        correct[\"learning_rate\"] = optimizer.param_groups[0]['lr']\n",
        "        if np.isnan(valid_loss):\n",
        "            print(f\"NaN detected in loss at Epoch {epoch}. Stopping training.\")\n",
        "            break\n",
        "        valid_loss_arr.append(valid_loss)\n",
        "        correct_valid.append(correct)\n",
        "        df = pd.DataFrame([correct])\n",
        "        df.to_csv(csv_file_eval, mode='a', header=not pd.io.common.file_exists(csv_file_eval), index=False)\n",
        "        epoch+=1\n",
        "        alpha, run = new_alpha(alpha, changing_alpha, epoch, max_epochs,valid_loss_arr )\n",
        "        scheduler.step()\n",
        "        if(correct[\"count_error\"]<min_count_error):\n",
        "          min_count_error = correct[\"count_error\"]\n",
        "          torch.save(model.state_dict(), f\"model_{model_name}.pth\")\n",
        "    return train_loss_arr, valid_loss_arr, correct_train, correct_valid, model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YmqFq4O4vaoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GIvj_ZKuBbj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "alphas = [ 0, 1, 0.3]\n",
        "for a in alphas:\n",
        "  # Instantiate model and move to the correct device\n",
        "  model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "  model.apply(init_weights)\n",
        "  train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{a}_BCE_Loss\", alpha=a,regular_bce=True, lr=2e-4)\n",
        "  plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"alpha={a}_BCE\")\n",
        "  model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "  model.apply(init_weights)\n",
        "  train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{a}_Facal_Loss\", alpha=a,regular_bce=False, lr=2e-4)\n",
        "  plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"alpha={a}_Facal\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bQ3EhIFIwvX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLItW3kIn_JT"
      },
      "outputs": [],
      "source": [
        "#Run changing alphas for decrease alpha (starting from alpha=1) and increase alpha (starting from alpha=0)\n",
        "\"\"\"\n",
        "model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "model.apply(init_weights)\n",
        "train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{1}_BCE_Loss_decreasing_dynamic_epochs\", alpha=1,regular_bce=True, lr=2e-4, changing_alpha=4)\n",
        "plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"decrease alpha dynamicly - BCE Loss\")\n",
        "model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "model.apply(init_weights)\n",
        "train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{1}_BCE_Loss_decreasing_every_2_epochs\", alpha=1,regular_bce=True, lr=2e-4, changing_alpha=2)\n",
        "plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"decrease alpha every 2 epochs - BCE Loss\")\n",
        "#Run alpha=1\n",
        "model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "model.apply(init_weights)\n",
        "train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{1}_BCE_Loss\", alpha=1,regular_bce=True, lr=2e-4)\n",
        "plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"alpha={1}_BCE\")\n",
        "model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "model.apply(init_weights)\n",
        "train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{1}_Focal_Loss\", alpha=1,regular_bce=False, lr=2e-4)\n",
        "plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"alpha={1}_Focal\")\n",
        "\"\"\"\n",
        "model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "model.apply(init_weights)\n",
        "train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{0}_BCE_Loss_increase_every_2_epochs\", alpha=0,regular_bce=True, lr=2e-4, changing_alpha=1)\n",
        "plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"increase alpha every 2 epochs - BCE Loss\")\n",
        "#Run changing alphas\n",
        "model = MambaBirdClassifier(device=device, n_classes=len(avi_set), seq_len=1700).to(device)\n",
        "model.apply(init_weights)\n",
        "train_loss_arr, valid_loss_arr, correct_train, correct_valid, trained_model = train_and_eval_mamba(model, train_loader, valid_loader, model_name=f\"final_alpha:{0}_BCE_Loss_increase_dynamic_epochs\", alpha=0,regular_bce=True, lr=2e-4, changing_alpha=3)\n",
        "plot_epoch_metrics_with_alpha_and_learning_rate(correct_train, correct_valid,  title=f\"increase alpha every 2 epochs - BCE Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzlUtkWfC4j3"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss_arr, label='Training Loss')\n",
        "plt.plot(valid_loss_arr, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot([correct_train_arr[i][\"count\"] for i in range(len(correct_train_arr))], label='Training')\n",
        "plt.plot([correct_valid_arr[i][\"count\"] for i in range(len(correct_valid_arr))], label='Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Count Accuracy')\n",
        "plt.title('Training and Validation Count Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot([correct_train_arr[i]['bird classifier'] for i in range(len(correct_train_arr))], label='Training')\n",
        "plt.plot([correct_valid_arr[i]['bird classifier'] for i in range(len(correct_valid_arr))], label='Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification Accuracy')\n",
        "plt.title('Training and Validation Classification Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiVLNYPlQEQY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYBstJqZKGIm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def evaluate_model(model, test_loader, device, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set and compute accuracy & classification report.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model.\n",
        "        test_loader: DataLoader for the test dataset.\n",
        "        device: The device (CPU/GPU) to run the evaluation on.\n",
        "        threshold: The threshold for multi-label classification (default=0.5).\n",
        "\n",
        "    Returns:\n",
        "        accuracy: The accuracy of the model on the test dataset.\n",
        "        classification_report: Detailed classification report.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for feats, target, ids in test_loader:\n",
        "            feats, target = feats.to(device), target.to(device)\n",
        "\n",
        "            # Forward pass through model\n",
        "            logits = model(feats)  # Get model outputs\n",
        "            probs = torch.sigmoid(logits)  # Apply sigmoid activation\n",
        "\n",
        "            # Apply threshold to get binary predictions\n",
        "            preds = (probs > threshold).int()\n",
        "\n",
        "            # Move predictions and labels to CPU\n",
        "            preds_np = preds.cpu().numpy()\n",
        "            target_np = target.cpu().numpy()\n",
        "\n",
        "            # Collect all predictions and labels\n",
        "            all_preds.append(preds_np)\n",
        "            all_labels.append(target_np)\n",
        "\n",
        "            # Print example predictions\n",
        "            for i in range(len(preds_np)):\n",
        "                decoded_pred = decode_birds(preds_np[i], bird_to_index)  # Decoded prediction\n",
        "                decoded_target = decode_birds(target_np[i], bird_to_index)  # Decoded target\n",
        "                print(f\"Item {i}:\")\n",
        "                print(f\"Predicted Birds: {decoded_pred}\")\n",
        "                print(f\"Target Birds: {decoded_target}\")\n",
        "\n",
        "    # Convert list of batches into a single numpy array\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    # Compute accuracy and classification report\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(all_labels.shape[1])])\n",
        "\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# After training\n",
        "evaluate_model(model, test_loader, device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}